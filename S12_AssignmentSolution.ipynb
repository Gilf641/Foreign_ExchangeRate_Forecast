{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "S12_AssignmentSolution.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1wZtHsvQWJkxTyCJVuglx02CHTeJKd0CW",
      "authorship_tag": "ABX9TyNEvsoHTSpkg0JSY0k35UyZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "86d7b4ed921d43b6ab4ced0154b1408a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_41a589fdc1bf42f294b3a061ead610dd",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2420e6e578fd4d01b98912c80f4a2194",
              "IPY_MODEL_577d31b1b43344f28d5a9aaa04509018"
            ]
          }
        },
        "41a589fdc1bf42f294b3a061ead610dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2420e6e578fd4d01b98912c80f4a2194": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_82b22c0fe3fc4ada98f3ce9960460f30",
            "_dom_classes": [],
            "description": "  0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 100,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_af644d3894d94ee08de316b9554a7560"
          }
        },
        "577d31b1b43344f28d5a9aaa04509018": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1ee9b971860a43b787ab55ce6b782a0e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/100 [00:01&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_62f32e1e94be436bb09c789324400180"
          }
        },
        "82b22c0fe3fc4ada98f3ce9960460f30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "af644d3894d94ee08de316b9554a7560": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1ee9b971860a43b787ab55ce6b782a0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "62f32e1e94be436bb09c789324400180": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gilf641/Foreign_ExchangeRate_Forecast/blob/master/S12_AssignmentSolution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhOCzNUufoKv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "outputId": "3f915351-d23b-423b-cf59-8b9c75b9071f"
      },
      "source": [
        "from __future__ import print_function\n",
        "%matplotlib inline\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BIMgFOIfoFm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "4a411a26-a338-4076-a91e-da89c85179f5"
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/EVA4/updLib2/evaLibrary')\n",
        "!ls '/content/drive/My Drive/EVA4/updLib2/evaLibrary'\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AlbTestTransforms.py   customNet.py    execute.py    resNet.py\n",
            "AlbTrainTransforms.py  cyclicLR.py     Gradcam.py    rohan_library.py\n",
            "albumentations.py      DataLoaders.py  LR_Finder.py\n",
            "all.py\t\t       displayData.py  __pycache__\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SS5XnRH5f2af",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "53fbef7c-0da3-4a46-de0e-438cbe782d52"
      },
      "source": [
        "import execute\n",
        "from resNet import ResNet18\n",
        "import displayData as display\n",
        "import Gradcam as gdc\n",
        "import albumentations as alb\n",
        "# import DataLoaders as loader\n",
        "import AlbTestTransforms\n",
        "import AlbTrainTransforms\n",
        "import LR_Finder as lrf\n",
        "import cyclicLR as clr\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:LR_Finder:To enable mixed precision training, please install `apex`. Or you can re-install this package by the following command:\n",
            "  pip install torch-lr-finder -v --global-option=\"amp\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyqBXsyrb6QF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "outputId": "31bc17e1-8383-4ea9-a42a-d1f7ad521b34"
      },
      "source": [
        "!wget http://cs231n.stanford.edu/tiny-imagenet-200.zip"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-24 16:17:49--  http://cs231n.stanford.edu/tiny-imagenet-200.zip\n",
            "Resolving cs231n.stanford.edu (cs231n.stanford.edu)... 171.64.68.10\n",
            "Connecting to cs231n.stanford.edu (cs231n.stanford.edu)|171.64.68.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 248100043 (237M) [application/zip]\n",
            "Saving to: ‘tiny-imagenet-200.zip’\n",
            "\n",
            "tiny-imagenet-200.z 100%[===================>] 236.61M  17.5MB/s    in 17s     \n",
            "\n",
            "2020-06-24 16:18:06 (13.9 MB/s) - ‘tiny-imagenet-200.zip’ saved [248100043/248100043]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Izr1Mqqc2_Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "ba341f39-67b7-4236-c43d-75ce6f8f2613"
      },
      "source": [
        "!unzip -q tiny-imagenet-200.zip && ls tiny-imagenet-200"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "replace tiny-imagenet-200/words.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "test  tiny-imagenet-200  train\tval  wnids.txt\twords.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtKmLBZufmZ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "defaultPath = \"/content/tiny-imagenet-200/\"\n",
        "trainPath = defaultPath+\"train\"\n",
        "testPath = defaultPath+\"test\"\n",
        "valPath = defaultPath+\"val\"\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lu8pWNTyntcJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SK7uqRKkeva_",
        "colab_type": "text"
      },
      "source": [
        "**DataLoader part**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRK-sBGtgou3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision.datasets as datasets\n",
        "import torch.utils.data as data\n",
        "import os"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWhWWsMDevIQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "outputId": "394e6e6e-ecf8-4a1e-d997-98cfca516330"
      },
      "source": [
        "num_workers = {\"train\":4, \"val\":0, \"test\":0}\n",
        "transforms = {\"train\": AlbTrainTransforms.train_transforms(), \"val\": AlbTestTransforms.test_transforms(), \"test\": AlbTestTransforms.test_transforms()}\n",
        "\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(defaultPath, x), transforms[x]) for x in [\"train\", \"val\", \"test\"]}\n",
        "dataLoaders = {x: data.DataLoader(image_datasets[x], batch_size=128, shuffle=True, num_workers=num_workers[x], pin_memory=True) for x in [\"train\", \"val\", \"test\"]}\n",
        "sizeofDataset = {x: len(image_datasets[x]) for x in [\"train\", \"val\", \"test\"]}\n",
        "\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-8594a61160ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtransforms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAlbTrainTransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_transforms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"val\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAlbTestTransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_transforms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"test\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAlbTestTransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_transforms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mimage_datasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefaultPath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"val\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"test\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdataLoaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_datasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpin_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"val\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"test\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0msizeofDataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_datasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"val\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"test\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-8594a61160ad>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtransforms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAlbTrainTransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_transforms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"val\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAlbTestTransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_transforms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"test\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAlbTestTransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_transforms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mimage_datasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefaultPath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"val\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"test\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdataLoaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_datasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpin_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"val\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"test\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0msizeofDataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_datasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"val\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"test\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[1;32m    204\u001b[0m                                           \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m                                           \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m                                           is_valid_file=is_valid_file)\n\u001b[0m\u001b[1;32m    207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[1;32m     92\u001b[0m         super(DatasetFolder, self).__init__(root, transform=transform,\n\u001b[1;32m     93\u001b[0m                                             target_transform=target_transform)\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_find_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_valid_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m_find_classes\u001b[0;34m(self, dir)\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mNo\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0msubdirectory\u001b[0m \u001b[0mof\u001b[0m \u001b[0manother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \"\"\"\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/tiny-imagenet-200/train'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nx1-sy2m8nI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "outputId": "d9800597-7750-4318-cd14-e8c5f73d2263"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "how_many_to_plot = 100\n",
        "\n",
        "train_loader = dataLoaders[\"train\"]\n",
        "\n",
        "def show_images_horizontally(images, labels=[], un_normalize=False, fig_size=(15, 7)):\n",
        "    \"\"\"Show images in jupyter notebook horizontally w/ labels as title.\n",
        "    Parameters\n",
        "    ----------\n",
        "    images: pytorch Tensor of shape (#images, #channels, height, width)\n",
        "    labels: pytorch Tensor of shape (#images, label)\n",
        "        labels should be encoded in number like 0, 1 .. and so on.\n",
        "    un_normalize: bool\n",
        "        indicate whether to perform unnormalization operation for rendering.\n",
        "    fig_size: tuple\n",
        "    \"\"\"\n",
        "\n",
        "    fig = plt.figure(figsize=fig_size)\n",
        "    num_imgs = images.shape[0]\n",
        "    for i in range(num_imgs):\n",
        "        fig.add_subplot(1, num_imgs, i + 1)\n",
        "\n",
        "        # render image tensor\n",
        "        img = images[i]\n",
        "        npimg = img.numpy()\n",
        "        if un_normalize:\n",
        "            npimg = npimg / 2 + 0.5\n",
        "        npimg = np.transpose(npimg, (1, 2, 0))\n",
        "\n",
        "        # generate label as title\n",
        "        if labels:\n",
        "            plt.title(lookup_label[labels[i][0]])\n",
        "        plt.imshow(npimg, cmap='Greys_r')\n",
        "        plt.axis('off')\n",
        "\n",
        "# for i, batch in enumerate(train_loader, start=1):\n",
        "#   image, label = batch\n",
        "#   print(label)\n",
        "# plt.figure(figsize = (75 ,75))\n",
        "# for i, batch in enumerate(train_loader, start=1):\n",
        "#   image, label = batch\n",
        "#   print(label)\n",
        "#   # print(max(label[:]))\n",
        "#   # show_images_horizontally(image, un_normalize=True)\n",
        "\n",
        " "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-8d5457d20d3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mhow_many_to_plot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataLoaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mshow_images_horizontally\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mun_normalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfig_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'dataLoaders' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gsA1rqoE759",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3ede8607-74c6-4910-b418-03957caf644e"
      },
      "source": [
        "from torchsummary import summary\n",
        "import torch\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device('cuda' if use_cuda else 'cpu')\n",
        "print('Device set to ', device)\n",
        "\n",
        "model = ResNet18().to(device)\n",
        "summary(model, input_size=(3,32,32))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device set to  cuda\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,728\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "            Conv2d-3           [-1, 64, 32, 32]          36,864\n",
            "       BatchNorm2d-4           [-1, 64, 32, 32]             128\n",
            "            Conv2d-5           [-1, 64, 32, 32]          36,864\n",
            "       BatchNorm2d-6           [-1, 64, 32, 32]             128\n",
            "        BasicBlock-7           [-1, 64, 32, 32]               0\n",
            "            Conv2d-8           [-1, 64, 32, 32]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 32, 32]             128\n",
            "           Conv2d-10           [-1, 64, 32, 32]          36,864\n",
            "      BatchNorm2d-11           [-1, 64, 32, 32]             128\n",
            "       BasicBlock-12           [-1, 64, 32, 32]               0\n",
            "           Conv2d-13          [-1, 128, 16, 16]          73,728\n",
            "      BatchNorm2d-14          [-1, 128, 16, 16]             256\n",
            "           Conv2d-15          [-1, 128, 16, 16]         147,456\n",
            "      BatchNorm2d-16          [-1, 128, 16, 16]             256\n",
            "           Conv2d-17          [-1, 128, 16, 16]           8,192\n",
            "      BatchNorm2d-18          [-1, 128, 16, 16]             256\n",
            "       BasicBlock-19          [-1, 128, 16, 16]               0\n",
            "           Conv2d-20          [-1, 128, 16, 16]         147,456\n",
            "      BatchNorm2d-21          [-1, 128, 16, 16]             256\n",
            "           Conv2d-22          [-1, 128, 16, 16]         147,456\n",
            "      BatchNorm2d-23          [-1, 128, 16, 16]             256\n",
            "       BasicBlock-24          [-1, 128, 16, 16]               0\n",
            "           Conv2d-25            [-1, 256, 8, 8]         294,912\n",
            "      BatchNorm2d-26            [-1, 256, 8, 8]             512\n",
            "           Conv2d-27            [-1, 256, 8, 8]         589,824\n",
            "      BatchNorm2d-28            [-1, 256, 8, 8]             512\n",
            "           Conv2d-29            [-1, 256, 8, 8]          32,768\n",
            "      BatchNorm2d-30            [-1, 256, 8, 8]             512\n",
            "       BasicBlock-31            [-1, 256, 8, 8]               0\n",
            "           Conv2d-32            [-1, 256, 8, 8]         589,824\n",
            "      BatchNorm2d-33            [-1, 256, 8, 8]             512\n",
            "           Conv2d-34            [-1, 256, 8, 8]         589,824\n",
            "      BatchNorm2d-35            [-1, 256, 8, 8]             512\n",
            "       BasicBlock-36            [-1, 256, 8, 8]               0\n",
            "           Conv2d-37            [-1, 512, 4, 4]       1,179,648\n",
            "      BatchNorm2d-38            [-1, 512, 4, 4]           1,024\n",
            "           Conv2d-39            [-1, 512, 4, 4]       2,359,296\n",
            "      BatchNorm2d-40            [-1, 512, 4, 4]           1,024\n",
            "           Conv2d-41            [-1, 512, 4, 4]         131,072\n",
            "      BatchNorm2d-42            [-1, 512, 4, 4]           1,024\n",
            "       BasicBlock-43            [-1, 512, 4, 4]               0\n",
            "           Conv2d-44            [-1, 512, 4, 4]       2,359,296\n",
            "      BatchNorm2d-45            [-1, 512, 4, 4]           1,024\n",
            "           Conv2d-46            [-1, 512, 4, 4]       2,359,296\n",
            "      BatchNorm2d-47            [-1, 512, 4, 4]           1,024\n",
            "       BasicBlock-48            [-1, 512, 4, 4]               0\n",
            "           Linear-49                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 11,173,962\n",
            "Trainable params: 11,173,962\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 11.25\n",
            "Params size (MB): 42.63\n",
            "Estimated Total Size (MB): 53.89\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPa5irH1sy5W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "CUDA_LAUNCH_BLOCKING=1 \n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-7, weight_decay=1e-2)\n",
        "\n",
        "# lr_finder = LRFinder(model, optimizer, criterion, device=\"cuda\")\n",
        "# lr_finder.range_test(train_loader, end_lr=100, num_iter=100, step_mode=\"exp\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nztMxZ6PJqw8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clr.lr_rangetest(device, model, train_loader, criterion, 0.0001, 0.001, 40)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXR2cgav0-UZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import csv\n",
        "import random\n",
        "import requests\n",
        "import zipfile\n",
        "import numpy as np\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class tinyImageDataset:\n",
        "\n",
        "    def __init__(self, \n",
        "                path,\n",
        "                train = True, \n",
        "                download=True, \n",
        "                splitRatio=0.70, \n",
        "                random_seed=110, \n",
        "                transform=None):\n",
        "        self.path=path\n",
        "        self.train=train\n",
        "        self.download=download\n",
        "        self.splitRatio=splitRatio\n",
        "        self.random_seed=random_seed\n",
        "        self.transform=transform\n",
        "\n",
        "        # download the dataset\n",
        "        if download:\n",
        "            self.downloadDataset()\n",
        "        \n",
        "        if splitRatio > 1:\n",
        "            raise ValueError(\"train_split must be less than 1\")\n",
        "\n",
        "        self._classID = self._mapID_to_className()  \n",
        "        self.data, self.target = self._loadData(self.train)\n",
        "        print(\"data \", self.data)\n",
        "        # print(\"target \", len(self.target))\n",
        "\n",
        "        # shuffle the dataset\n",
        "        self._imageIndex = np.arange(len(self.target))\n",
        "        np.random.seed(random_seed)\n",
        "        np.random.shuffle(self._imageIndex)\n",
        "\n",
        "        # Split the data using Image indices\n",
        "        print(\"ImageIndices\", len(self._imageIndex))\n",
        "        splitValue = int(len(self._imageIndex)*self.splitRatio) \n",
        "        print(\"SplitValue\", splitValue)\n",
        "        self._imageIndex = self._imageIndex[:splitValue] if self.train else self._imageIndex[splitValue:]\n",
        "\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._imageIndex) \n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image_index = self._imageIndex[index]\n",
        "        image = self.data[image_index]   \n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, self.target[image_index]\n",
        "\n",
        "    \n",
        "    def __repr__(self):\n",
        "        head = 'TinyImageNet Dataset'\n",
        "        body = ['Number of datapoints: {}'.format(self.__len__())]\n",
        "        if self.path is not None:\n",
        "            body.append('Root Location: {}'.format(self.path))\n",
        "        body += [f'Split: {\"Train\" if self.train else \"Test\"}']\n",
        "        if hasattr(self, 'transforms') and self.transforms is not None:\n",
        "            body += [repr(self.transforms)]\n",
        "        lines = [head] + [' ' * 4 + line for line in body]\n",
        "        return '\\n'.join(lines)\n",
        "\n",
        "\n",
        "    def tinyClasses(self):\n",
        "        return tuple(cls[1]['name']  for cls in sorted(self._classID, key=lambda x:x[1]['id']))     \n",
        "\n",
        "    def _mapID_to_className(self):\n",
        "        with open(os.path.join(self.path, 'tiny-imagenet-200/wnids.txt')) as f:\n",
        "            class_ids = {x[:-1]: '' for x in f.readlines()} \n",
        "\n",
        "        with open(os.path.join(self.path, 'tiny-imagenet-200/words.txt')) as f:\n",
        "            class_id = 0\n",
        "            for line in csv.reader(f, delimiter='\\t'):\n",
        "                if line[0] in class_ids:\n",
        "                    class_ids[line[0]] = {\"name\": line[1], \"id\": class_id}\n",
        "                    class_id += 1\n",
        "        \n",
        "        return class_ids \n",
        "\n",
        "    def _loadImage(self, image_path):\n",
        "        img = Image.open(image_path)\n",
        "\n",
        "        if img.mode == 'L':\n",
        "            img_array = np.array(img)#convert image to np array\n",
        "            print(img_array.shape) \n",
        "            img = np.stack((img_array,)*3, axis=-1)\n",
        "            img = Image.fromarray(img.astype('uint8'), 'RGB') #converting the np image back normal\n",
        "\n",
        "        return img\n",
        "    \n",
        "    def _loadData(self, train = True):\n",
        "        data = []\n",
        "        target = []\n",
        "        \n",
        "        if train:\n",
        "          train_path = os.path.join(self.path, \"tiny-imagenet-200/train\")\n",
        "          for classDir in os.listdir(train_path):\n",
        "              trainData_path = os.path.join(train_path, classDir+\"/images\")\n",
        "              for image in os.listdir(trainData_path):\n",
        "                  data.append(self._loadImage(os.path.join(trainData_path, image)))\n",
        "                  target.append(self._classID[classDir][\"id\"])\n",
        "                    \n",
        "      \n",
        "        else:\n",
        "          val_path = os.path.join(self.path, 'tiny-imagenet-200/val')\n",
        "          valImages_path = os.path.join(val_path, 'images')\n",
        "          with open(os.path.join(val_path, 'val_annotations.txt')) as f:\n",
        "              for line in csv.reader(f, delimiter='\\t'):\n",
        "                  data.append(self._loadImage(os.path.join(valImages_path, line[0])))\n",
        "                  target.append(self._classID[line[1]]['id'])\n",
        "        \n",
        "        print('datalen: ', len(data))\n",
        "        print('targetlen: ', len(target))\n",
        "        return data, target\n",
        "    \n",
        "    def downloadDataset(self):\n",
        "        if not os.path.exists(self.path):\n",
        "            r = requests.get('http://cs231n.stanford.edu/tiny-imagenet-200.zip', stream=True)\n",
        "            zip_ref = zipfile.ZipFile(BytesIO(r.content))\n",
        "            zip_ref.extractall(os.path.dirname(self.path))\n",
        "            zip_ref.close()\n",
        "\n",
        "            # # Move file to appropriate location\n",
        "            # os.rename(os.path.join(os.path.dirname(self.path), 'tiny-imagenet-200'), self.path)\n",
        "        else:\n",
        "            print('Files already downloaded.')\n",
        "\n",
        "def loader(trainData, valData, train=True):\n",
        "        loader_args = {\n",
        "            'batch_size': 128,\n",
        "            'num_workers': 4,\n",
        "            'pin_memory': True,\n",
        "            'cuda': True\n",
        "        }\n",
        "\n",
        "        return data_loader(\n",
        "            trainData, **loader_args\n",
        "        ) if train else data_loader(valData, **loader_args)\n",
        "\n",
        "\n",
        "def data_loader(data, shuffle=True, batch_size=1, num_workers=1, pin_memory=True, cuda=True):\n",
        "    \n",
        "    loader_args = {\n",
        "        'shuffle': shuffle,\n",
        "        'batch_size': batch_size\n",
        "    }\n",
        "\n",
        "    # If GPU exists\n",
        "    if cuda:\n",
        "        loader_args['num_workers'] = num_workers\n",
        "        loader_args['pin_memory'] = True\n",
        "    \n",
        "    return torch.utils.data.DataLoader(data, **loader_args)\n"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SV6r_YLXiG1L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision import datasets, transforms\n",
        "# albTrain = AlbTrainTransforms.train_transforms()\n",
        "# albTest = AlbTestTransforms.test_transforms()\n",
        "mainTransform = transforms.Compose([transforms.ToTensor(),\n",
        "                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0s0jjcdXWT3D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9aee1e44-a850-4b97-d773-5b95407f7bbb"
      },
      "source": [
        "defaultPath = \"/content/tiny-imagenet-200/\"\n",
        "train_dataset = tinyImageDataset(defaultPath, \n",
        "                train=True,\n",
        "                download=True,                    \n",
        "                splitRatio=0.70, \n",
        "                random_seed=110, \n",
        "                transform=mainTransform)\n",
        "\n",
        "\n",
        "val_dataset = tinyImageDataset(defaultPath,\n",
        "                train=False,\n",
        "                download=True, \n",
        "                random_seed=110, \n",
        "                transform=mainTransform)\n"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded.\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-118-43f2a61c9217>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m                 \u001b[0msplitRatio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.70\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                 \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m110\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                 transform=mainTransform)\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-116-bb9db55e6224>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, train, download, splitRatio, random_seed, transform)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_classID\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mapID_to_className\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loadData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m# print(\"target \", len(self.target))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-116-bb9db55e6224>\u001b[0m in \u001b[0;36m_loadData\u001b[0;34m(self, train)\u001b[0m\n\u001b[1;32m    113\u001b[0m               \u001b[0mtrainData_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassDir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/images\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m               \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainData_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m                   \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loadImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainData_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m                   \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_classID\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclassDir\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-116-bb9db55e6224>\u001b[0m in \u001b[0;36m_loadImage\u001b[0;34m(self, image_path)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_loadImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'L'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2816\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2818\u001b[0;31m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2820\u001b[0m     \u001b[0mpreinit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/signal_handling.py\u001b[0m in \u001b[0;36mhandler\u001b[0;34m(signum, frame)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;31m# This following call uses `waitid` with WNOHANG from C side. Therefore,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;31m# Python can still get and update the process status successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0m_error_if_any_worker_fails\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprevious_handler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mprevious_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid 2219) is killed by signal: Killed. "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmS2YjRheLJ5",
        "colab_type": "text"
      },
      "source": [
        "#Not sure about the split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z56sTg3pecbP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainLoader = loader(train_dataset, val_dataset, train=True)\n",
        "valLoader = loader(train_dataset, val_dataset, train=False)\n"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOxxJ_DYf3x5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "86d7b4ed921d43b6ab4ced0154b1408a",
            "41a589fdc1bf42f294b3a061ead610dd",
            "2420e6e578fd4d01b98912c80f4a2194",
            "577d31b1b43344f28d5a9aaa04509018",
            "82b22c0fe3fc4ada98f3ce9960460f30",
            "af644d3894d94ee08de316b9554a7560",
            "1ee9b971860a43b787ab55ce6b782a0e",
            "62f32e1e94be436bb09c789324400180"
          ]
        },
        "outputId": "c209a63b-706d-4ab2-eb18-ff04ebb62c5c"
      },
      "source": [
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "CUDA_LAUNCH_BLOCKING=1 \n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-7, weight_decay=1e-2)\n",
        "\n",
        "lr_finder =lrf.LRFinder(model, optimizer, criterion, device=\"cuda\")\n",
        "lr_finder.range_test(trainLoader, end_lr=100, num_iter=100, step_mode=\"exp\")\n",
        "\n"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "86d7b4ed921d43b6ab4ced0154b1408a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-111-3d8e7ed6aba7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mlr_finder\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mlrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLRFinder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mlr_finder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrange_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"exp\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/EVA4/updLib2/evaLibrary/LR_Finder.py\u001b[0m in \u001b[0;36mrange_test\u001b[0;34m(self, train_loader, val_loader, start_lr, end_lr, num_iter, step_mode, smooth_f, diverge_th, accumulation_steps, non_blocking_transfer)\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0;31m# Train on batch and retrieve loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m                 \u001b[0;31m# print(train_iter)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccumulation_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking_transfer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnon_blocking_transfer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/EVA4/updLib2/evaLibrary/LR_Finder.py\u001b[0m in \u001b[0;36m_train_batch\u001b[0;34m(self, train_iter, accumulation_steps, non_blocking_transfer)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m             \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/EVA4/updLib2/evaLibrary/resNet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavg_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1608\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1609\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1610\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1611\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1612\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: size mismatch, m1: [128 x 2048], m2: [512 x 10] at /pytorch/aten/src/THC/generic/THCTensorMathBlas.cu:283"
          ]
        }
      ]
    }
  ]
}